{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"A0112101M.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BYkyeU7mNYCs"},"source":["# Welcome!\n","\n","Welcome, CS5260 learners! \n","To minimize the effect of potential result shifts caused by the differences between hardware architectures, your project will be evaluated here on Google Colab.\n","\n","Please read the following before you start.\n","\n","- All the instructions below assume you are running this notebook on Google Colab. You can run and debug this notebook using Jupyter notebook with minor modification.\n","- Check Google Colab's [tutorial](https://colab.research.google.com/notebooks/welcome.ipynb#)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rkGwDfgpTSmM","colab":{}},"source":["# Replace A0123456X with your matriculation number.\n","MATRIC_NUM = 'A0112101M'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"E9R5D2yL304P"},"source":["# Introduction"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MDu00DO_aKEE"},"source":["## Filesystem"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WMmpXyvhaO8w"},"source":["Due to the special file system Google Colab uses, coding here will be a little bit different from coding on your local machine.\n","\n","Here's what will happen when the following block runs on our side.\n","1. The TA's Google Drive will be mounted with the virtual machine that runs this Colab notebook, at `/content/drive/My Drive/`\n","2. A special variable `ROOT` will be set to `/content/drive/My Drive/CS5260/`\n","3. This `ROOT` variable, along with your matriculation number, will be used to locate resources related to your submission.\n","\n","The filesystem will look like this:\n","\n","```\n","/content/drive/My Drive/CS5260/ (ROOT)\n","  |____ model\n","  |  |____ model.pt\n","  |____ images\n","  |  |____ artifacts\n","  |  |  |____ 0000.png\n","  |  |  |____ 0001.png\n","  |  |  |____ ...\n","  |  |____ cancer_regions\n","  |  |  |____ XXXX.png\n","  |  |  |____ XXXX.png\n","  |  |  |____ ...\n","  |  |____ ...\n","  |____ results\n","  |  |____ MATRIC_NUM.txt\n","  |____ MATRIC_NUM\n","     |____ MATRIC_NUM.ipynb\n","     |____ other_supporting_files\n","     |____ ...\n","```\n","\n","Therefore, in your algorithm, please use `os.path.join(ROOT, \"model\")` to replace `../model/`, the same applies to `../images` and `../results/`.\n","\n","You can debug your code by creating the same folders on your Google Drive."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Vt64arlcb6EY","outputId":"cef8ec75-7979-415f-b70d-2b4555fa5677","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1586082684646,"user_tz":-480,"elapsed":20638,"user":{"displayName":"T SW","photoUrl":"","userId":"12897501351850012858"}}},"source":["import sys\n","import os.path as osp\n","ROOT = 'C:\\\\Users\\\\tey_s\\\\Desktop\\\\CS5260'\n","\n","# Colab: uncomment\n","from google.colab import drive\n","drive.mount('/content/drive')\n","ROOT = osp.join('/content', 'drive', 'My Drive', 'CS5260')\n","sys.path.append(osp.join(ROOT, MATRIC_NUM))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Y_c8j5AsnKRT"},"source":["# Preparation"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_GeatXrgnVFP"},"source":["## Runtime Setup\n","\n","Before running any code block, click \"Runtime\" in the menu bar and select \"Change runtime type\". In the popup window, change \"hardware accelerator\" to \"GPU\". If the following code block works, your environment should be ok.\n","\n","Run the following cell to determine the device type of your machine."]},{"cell_type":"code","metadata":{"cellView":"code","colab_type":"code","id":"N9eTijTgEYP7","outputId":"1e7d71c3-4aa3-4b7f-a046-f43e5681416d","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1586082687777,"user_tz":-480,"elapsed":23761,"user":{"displayName":"T SW","photoUrl":"","userId":"12897501351850012858"}}},"source":["import torch\n","if torch.cuda.is_available():\n","  print(\"GPU is available.\")\n","  device = torch.device('cuda')\n","else:\n","  print(\"Change runtime type to GPU for better performance.\")\n","  device = torch.device('cpu')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["GPU is available.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"c60-2JC-c_0S"},"source":["## Libraries\n","\n","You can import libraries as in a Jupyter notebook. To install a library, use `!pip install package-name`.\n","\n","Please place all you imports in the following cell."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OQEmrtqcLrlW","outputId":"f09d90ff-4715-4d07-a637-d6c8d8c370c7","colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"status":"ok","timestamp":1586082700515,"user_tz":-480,"elapsed":36490,"user":{"displayName":"T SW","photoUrl":"","userId":"12897501351850012858"}}},"source":["# Colab: uncomment\n","!pip install adversarial-robustness-toolbox\n","from load_model_36 import load_model\n","\n","# Colab: comment\n","# from load_model_37 import load_model\n","\n","import torchvision\n","import torch\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import time\n","import datetime\n","import lightgbm as lgb\n","from copy import deepcopy\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","\n","from art.classifiers import PyTorchClassifier\n","from art.defences import TotalVarMin, ThermometerEncoding, SpatialSmoothing, PixelDefend, LabelSmoothing, JpegCompression, GaussianAugmentation, FeatureSqueezing\n","from art.defences import GaussianNoise, HighConfidence, ReverseSigmoid, Rounded, ClassLabels\n","\n","print('Import done!')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting adversarial-robustness-toolbox\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n","\r\u001b[K     |▊                               | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 4.7MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 6.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 6.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 71kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 102kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 112kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 122kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 133kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 143kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 153kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 163kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 174kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 184kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 194kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 204kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 215kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 225kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 235kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 245kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 256kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 266kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 276kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 286kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 296kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 307kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 317kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 327kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 337kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 348kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 358kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 368kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 378kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 389kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 399kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 409kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 419kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 430kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 440kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 450kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 460kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 471kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 481kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 491kB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.2)\n","Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n","Collecting scikit-learn==0.22.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 39.3MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.6)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n","Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n","Import done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NNNHVSaFYn42"},"source":["# Submission"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ciyW6Rrh4Bwd"},"source":["## How do I submit?\n","1. Place this notebook, along with all you supporting documents, in a folder named with your matriculation number.\n","2. Zip this folder, renamed the zip archive with your matriculation number.\n","3. Submit the zip archive using [this Google Form](https://forms.gle/A77s1N5tzu4XAr2QA) (Google account required)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XGwIw4-VWvig"},"source":["## How do I Add Supporting Libraries if it's not in Pip?\n","Please keep this in mind: `os.path.join(ROOT, MATRIC_NUM)` will point to the directory of your submission. This directory has also been added to `sys.path` in the code cell above. If your supporting libraries lie in deeper directories, e.g. `os.path.join(ROOT, MATRIC_NUM, 'libs')`, you may append `sys.path` with those directories.\n","\n","After adding all relevant directories to `sys.path`, you should be able to directly import them by the name of the modules."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"li0m_D3vm2J8"},"source":["# Now it's Your Turn\n","Please complete this notebook.\n","When evaluating your submission, we will directly open this notebook and click \"Runtime -> Run all\" in the menubar. Your result should then appear in `os.path.join(ROOT, 'results')` as `A0123456X.txt`. The format is quoted here:\n","\n","> This text file contains one entry per test image separated by a ‘newline’ character.\n","> Each entry must contain image id and your top-1 prediction separated by ‘#’, e.g. 1000#0.\n","\n","**We will not handle crashes.**"]},{"cell_type":"markdown","metadata":{"id":"uJ5uehzO1lNc","colab_type":"text"},"source":["# 1. Data Directories"]},{"cell_type":"code","metadata":{"id":"MnDMadTQ1lNd","colab_type":"code","colab":{}},"source":["# Data directories\n","image_dir = osp.join(ROOT, 'images')\n","main_dir = osp.join(ROOT,MATRIC_NUM)\n","lgb_dir = osp.join(ROOT,MATRIC_NUM,'lgb_model.txt')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j1wyd-yr1lNg","colab_type":"text"},"source":["# 2. Define Functions"]},{"cell_type":"code","metadata":{"id":"0z0WicXA1lNh","colab_type":"code","colab":{}},"source":["mean=[0.485, 0.456, 0.406]\n","std=[0.229, 0.224, 0.225]\n","normalize = transforms.Normalize(mean=[0,0,0], std=[1,1,1])\n","\n","class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n","    \"\"\"Custom dataset that includes image file paths. Extends\n","    torchvision.datasets.ImageFolder\n","    \"\"\"\n","\n","    # override the __getitem__ method. this is the method that dataloader calls\n","    def __getitem__(self, index):\n","        # this is what ImageFolder normally returns \n","        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n","        # the image file path\n","        path = self.imgs[index][0]\n","        # make a new tuple that includes original and the path\n","        tuple_with_path = (original_tuple + (path,))\n","        return tuple_with_path\n","    \n","def load_data(data_dir, batch_size = 25):\n","    data_loader = torch.utils.data.DataLoader(\n","        ImageFolderWithPaths(data_dir, transforms.Compose([\n","            transforms.Resize(128),\n","            transforms.CenterCrop(128),\n","            transforms.ToTensor(),\n","            normalize,])),\n","            batch_size=batch_size, \n","            num_workers=0)\n","    return data_loader\n","def write_results(image_set, data_folder = None, def_labels = None, path_set = None):\n","    if image_set == 'A0112101M':\n","        with open(osp.join(ROOT,'results','{}.txt'.format(image_set)), 'w') as the_file:\n","            the_file.write('')\n","\n","        for i in range(len(def_labels)):\n","            name = path_set[i].split('/')[-1]\n","            name = name.split('.')[0]\n","            with open(osp.join(ROOT,'results','{}.txt'.format(image_set)), 'a') as the_file:\n","                the_file.write('{}#{:.0f}\\n'.format(name,int(def_labels[i])))        \n","    else:\n","        if image_set == 'clean':\n","            image_dir = osp.join(ROOT, data_folder,'clean_images')\n","        elif image_set == 'adv':\n","            image_dir = osp.join(ROOT, data_folder,'adv_images')\n","\n","        clean_labels = []\n","        data_loader = load_data(image_dir) # load data\n","        for pre_img, clean_label, path in data_loader:\n","            if len(clean_labels)==0:\n","                path_set = path\n","            else:\n","                path_set = path_set + path\n","            clean_labels = np.concatenate([clean_labels,clean_label],axis=0)\n","\n","        with open(osp.join(ROOT,'results','{}.txt'.format(image_set)), 'w') as the_file:\n","            the_file.write('')\n","\n","        for i in range(len(clean_labels)):\n","            name = path_set[i].split('/')[-1]\n","            name = name.split('.')[0]\n","            with open(osp.join(ROOT,'results','{}.txt'.format(image_set)), 'a') as the_file:\n","                the_file.write('{}#{}\\n'.format(name,int(clean_labels[i])))\n","                \n","def eval_script():\n","    # Evaluation script\n","    import argparse\n","    import sys\n","    if sys.version_info[0] < 3 or sys.version_info[1] < 6:\n","        raise AssertionError(\"Please use Python 3.6+\")\n","\n","    usage = \"\"\"\n","\n","    This is the example evaluation script we will be using to calculate your accuracy.\n","    You score will be calculated as the harmonic mean of accuracy in clean and adversarial images, i.e.\n","    score = 2 / (1 / acc_clean + 1 / acc_adversarial)\"\"\"\n","\n","    def harmonic_mean(x1, x2):\n","        eps = 1e-7\n","        x1 = x1 + eps\n","        x2 = x2 + eps\n","        return 2 / (1 / x1 + 1 / x2)\n","\n","    def load_label(path):\n","        outputs = open(path, 'r').read().splitlines()\n","        outputs = {i.split('#')[0]: i.split('#')[1] for i in outputs}\n","        return outputs\n","\n","    p = argparse.ArgumentParser(usage=usage)\n","    required = p.add_argument_group('required arguments')\n","    required.add_argument('--pred-file', type=str, required=True, help='The output of your defense algorithm.')\n","    required.add_argument('--clean-label', type=str, required=False, help='The grounding truth of clean images by CS5260 staff')\n","    required.add_argument('--adv-label', type=str, required=False, help='The grounding truth of adversarial images by CS5260 staff')\n","    args = p.parse_args(args=['--pred-file',osp.join(ROOT,'results','A0112101M.txt'),'--clean-label',osp.join(ROOT,'results','clean.txt'),'--adv-label',osp.join(ROOT,'results','adv.txt')]) # Need to key in required arguments\n","\n","    pred        = load_label(args.pred_file)\n","    clean_label = load_label(args.clean_label)\n","    model_label   = load_label(args.adv_label)\n","    num_pred  = len(pred)\n","    num_clean = len(clean_label)\n","    num_adv   = len(model_label)\n","\n","    if num_adv + num_clean != num_pred:\n","        raise AssertionError(f'Number of your predictions {num_pred} does not match the number of labels {num_clean + num_adv}.')\n","\n","    clean_correct = 0\n","    adv_correct = 0\n","    for k, v in pred.items():\n","        if clean_label.get(k) == v:\n","            clean_correct += 1\n","        elif model_label.get(k) == v:\n","            adv_correct += 1\n","\n","    score = harmonic_mean(clean_correct / num_clean, adv_correct / num_adv)\n","    result = \"\"\"\n","    Evaluation result:\n","        Clean:       {} / {} correct.\n","        Adversarial: {} / {} correct.\n","        Score:       {:.4f}.\n","    \"\"\".format(clean_correct,num_clean,adv_correct,num_adv,score)\n","    print(result)\n","\n","def harmonic_mean(x1, x2):\n","    eps = 1e-7\n","    x1 = x1 + eps\n","    x2 = x2 + eps\n","    return 2 / (1 / x1 + 1 / x2)\n","\n","def unique(target): # return unique label counts\n","    uniq_target = target.unique(sorted=True)\n","    unique_count = torch.stack([(target==item).sum() for item in uniq_target])\n","#     for i in range(len(uniq_target)):\n","#         print(\"Label {}: {}\".format(uniq_target.numpy()[i],unique_count.numpy()[i]))\n","    return unique_count\n","\n","def denorm_img(image_set):\n","    img = deepcopy(image_set)\n","    for idx in range(img.shape[0]):\n","        for i in range(3):\n","            img[idx,i] = (img[idx,i]-mean[i])/std[i]\n","    return img\n","\n","def evaluate_def(clean_label, model_label, def_label):\n","\n","    model_good = 0\n","    def_good = 0\n","    num = int(len(model_label))\n","\n","    for i in range(num):\n","        if model_label[i] == clean_label[i]:\n","            model_good += 1\n","        if def_label[i] == clean_label[i]:\n","            def_good += 1\n","    num = num/100\n","    print('                [{:.2f}%,{:.2f}%]'.format(model_good/num,def_good/num))\n","    return def_good/num\n","\n","def print_results(clean_label, model_label, pre_label, post_label):\n","    print(\"Pre processing: [Model , Defended]\")\n","    pre_acc = evaluate_def(clean_label, model_label, pre_label) \n","    print(\"Postprocessing: [Model , Defended]\")\n","    post_acc = evaluate_def(clean_label, model_label, post_label)  \n","    return pre_acc, post_acc\n","    \n","def pre_process(pre_img, model, preprocess):\n","\n","    model_label = model(denorm_img(pre_img)).max(axis=1)[1].numpy()    \n","\n","    post_img,_ = preprocess(pre_img.numpy())\n","    preds = model(torch.from_numpy(denorm_img(post_img)).float())\n","    \n","    return model_label, post_img, preds\n","\n","def post_process(preds, bst): \n","    softmax = nn.Softmax(dim=-1)(preds)    \n","    def_label = torch.from_numpy(bst.predict(softmax)).max(dim=1)[1]\n","    return def_label   "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O2MPkijS1lNj","colab_type":"text"},"source":["# 3. Code to pre-train Lightgbm Model (Commented)"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"W_GCcag41lNj","colab_type":"code","colab":{}},"source":["# start_global = time.time() \n","# # Train post-processing\n","\n","# def print_score(label, pred, printout = False):\n","#     num = int(len(label))\n","#     score = 0\n","\n","#     for i in range(num):\n","#         if pred[i] == label[i]:\n","#             score += 1\n","            \n","#     if printout:\n","#         print('Score: ',score*100/num)        \n","#     return score*100/num\n","\n","# # Load models\n","# model = load_model(osp.join(ROOT, 'model','model.pt'), 'cpu')\n","# model.eval()\n","# preprocess = SpatialSmoothing(window_size=6, channel_index=1, clip_values=(0,1))\n","\n","# clean_labels = []\n","# data_loader = load_data(image_dir, batch_size = 25) # load data\n","# for pre_img, clean_label, path in data_loader:\n","#     model_label, post_img, preds = pre_process(pre_img, model, preprocess) # pre-process    \n","#     softmax = nn.Softmax(dim=-1)(preds)\n","#     # Store values\n","#     if len(clean_labels)==0:\n","#         softmaxes = softmax\n","#     else:\n","#         softmaxes = np.concatenate([softmaxes,softmax],axis=0)\n","#     clean_labels = np.concatenate([clean_labels,clean_label],axis=0)\n","    \n","# # Save results\n","# np.save(osp.join(main_dir,'lgb_xtrain'), softmaxes)\n","# np.save(osp.join(main_dir,'lgb_ytrain'), clean_labels)\n"," \n","# # Load pre-saved results\n","# softmaxes = np.load(osp.join(main_dir,'lgb_xtrain.npy'))\n","# clean_labels = np.load(osp.join(main_dir,'lgb_ytrain.npy'))\n","\n","# # Split data for Validation\n","# xtrain, xtest, ytrain, ytest = train_test_split(softmaxes, clean_labels, test_size=0.4, random_state = 40)\n","\n","# score = -50\n","# train_data = lgb.Dataset(xtrain, label=ytrain)\n","\n","# # Parameters set(After fine tuning) to search for the best params\n","# learning_rate = [0.1,0.15,0.2,0.3]\n","# leaf_no_set = [21,41,61]\n","# num_round_set = [50,100,150]\n","\n","# for lr in learning_rate:\n","#     for leaf_no in leaf_no_set:\n","#         for num_round in num_round_set:\n","#             param = {'num_leaves': leaf_no, 'objective': 'multiclass', 'num_class':4, 'learning_rate':lr}\n","\n","#             bst = lgb.train(param, train_data, num_round)\n","\n","#             model_label = np.argmax(xtest,axis=1)\n","#             post_label = torch.from_numpy(bst.predict(xtest)).max(dim=1)[1]\n","            \n","#             pre_score = print_score(ytest, model_label)\n","#             post_score = print_score(ytest, post_label)\n","            \n","#             if post_score-pre_score> score:\n","#                 # Update best params\n","#                 score = post_score-pre_score\n","#                 best_leaf = leaf_no\n","#                 best_round = num_round\n","#                 best_lr = lr\n","\n","#                 # Save model\n","#                 bst.save_model(lgb_dir)\n","\n","# # Predict whole dataset with best params\n","# param = {'num_leaves': best_leaf, 'objective': 'multiclass', 'num_class':4, 'learning_rate':best_lr}\n","\n","# bst = lgb.train(param, train_data, best_round)\n","# model_label = np.argmax(xtest,axis=1)\n","# post_label = torch.from_numpy(bst.predict(xtest)).max(dim=1)[1]\n","\n","# pre_score = print_score(ytest, model_label, printout=True)\n","# post_score = print_score(ytest, post_label, printout=True)\n","\n","# print('Best parameters:\\nLR {}, Leaf {}, Round {}, Score {}'.format(best_lr,best_leaf,best_round, score))\n","# print(\"Time taken: {:.2f}s\".format(time.time()-start_global))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z0vFIY191lNm","colab_type":"text"},"source":["# 4. Defense Algorithm"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iTFlBZRcUpGL","outputId":"0afcfaeb-2fc2-483e-d008-afd8ff8c59c7","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1586082809988,"user_tz":-480,"elapsed":145935,"user":{"displayName":"T SW","photoUrl":"","userId":"12897501351850012858"}}},"source":["###\n","start_global = time.time()\n","\n","# ------------- Defense algo starts here ----------------\n","# Load models\n","model = load_model(osp.join(ROOT, 'model','model.pt'), 'cpu')\n","model.eval()\n","preprocess = SpatialSmoothing(window_size=6, channel_index=1, clip_values=(0,1))\n","postprocess = lgb.Booster(model_file=lgb_dir)\n","\n","# Initialize sets\n","clean_labels = [] # Actual labels of the image set\n","model_labels = [] # Initial labels by model\n","def_labels = [] # Final labels after pre and post processes\n","predss = [] # Prediction results after pre process\n","path_set = [] # Image path names\n","\n","# load data\n","data_loader = load_data(image_dir)\n","\n","for pre_img, clean_label, path in data_loader:\n","    \n","    model_label, post_img, preds = pre_process(pre_img, model, preprocess) # pre-process\n","    def_label = post_process(preds, postprocess)                           # post-process\n","    \n","    # Store values\n","    clean_labels = np.concatenate([clean_labels,clean_label],axis=0)\n","    model_labels = np.concatenate([model_labels,model_label],axis=0)\n","    def_labels = np.concatenate([def_labels,def_label],axis=0)\n","    if len(predss)==0:\n","        predss = preds\n","        path_set = path\n","    else:\n","        predss = np.concatenate([predss,preds],axis=0)\n","        path_set = path_set + path\n","\n","pre_acc, post_acc = print_results(clean_labels, model_labels, np.argmax(predss,axis=1), def_labels)\n","\n","write_results('A0112101M',def_labels = def_labels, path_set = path_set)\n","# print(\"Time taken: {:.2f}s\".format(time.time()-start_global))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:478: UserWarning: Converting data to scipy sparse matrix.\n","  warnings.warn('Converting data to scipy sparse matrix.')\n"],"name":"stderr"},{"output_type":"stream","text":["Pre processing: [Model , Defended]\n","                [44.05%,62.56%]\n","Postprocessing: [Model , Defended]\n","                [44.05%,80.18%]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BWWVUjmg1lNq","colab_type":"text"},"source":["# 5. Evaluate Results (Commented)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"92FYTAxi1lNr","colab":{}},"source":["# # Colab: Comment\n","# data_folder = 'clean_adv'\n","# write_results('clean',data_folder)\n","# write_results('adv',data_folder)\n","# eval_script()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vZpmAtQCPX_t"},"source":["# Credits\n","\n","This Colab notebook is created for CS5260 final project. Feel free to clone, but please do not distribute. \n","\n","Last Edited: Mar-14-2020 20:00"]}]}