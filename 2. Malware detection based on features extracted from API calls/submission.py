import gc
import lightgbm as lgb
import numpy as np
import os
import pandas as pd
from functools import partial
from hyperopt import hp
from hyperopt import Trials
from hyperopt import fmin
from hyperopt import tpe
from hyperopt import STATUS_OK
from hyperopt import space_eval
from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from tqdm import tqdm

feature_pos = [[0, 8], [8, 12], [12, 28], [28, 44], [
    44, 52], [52, 64], [64, 80], [80, 92], [92, 102]]
FOLDER = 'freq'

def load_dataframe(id):
    train_data = np.load("train/train/{}.npy".format(id))
    return pd.DataFrame(data=train_data)


def load_test_dataframe(id):
    test_data = np.load("test/test/{}.npy".format(id))
    return pd.DataFrame(data=test_data)


def one_hot_encoding(encoder, dfs, col):
    if encoder == None:
        data = set(dfs[0][:, col])
        for i in range(1, len(dfs)):
            df = dfs[i]
            data |= set(df[:, col])
        encoder = OneHotEncoder(handle_unknown='ignore')
        encoder = encoder.fit([[str(e)] for e in data])
    encodedData = []
    for df in dfs:
        mat = np.sum(encoder.transform([[str(e)] for e in df[:, col]]), axis=0)
        mat = np.squeeze(np.asarray(mat))
        encodedData.append(mat)
    encodedData = np.stack(encodedData)
    return encoder, encodedData


def one_hot_encoding_feature(encoders, dfs, feature):
    if len(encoders) == 0:
        encoder, data = one_hot_encoding(None, dfs, feature_pos[feature][0])
        encoders.append(encoder)
        for col in tqdm(range(feature_pos[feature][0] + 1, feature_pos[feature][1])):
            encoder, dataCol = one_hot_encoding(None, dfs, col)
            encoders.append(encoder)
            data = np.concatenate((data, dataCol), axis=1)
    else:
        encoder, data = one_hot_encoding(
            encoders[0], dfs, feature_pos[feature][0])
        for col in tqdm(range(feature_pos[feature][0] + 1, feature_pos[feature][1])):
            i = col - feature_pos[feature][0]
            encoder, dataCol = one_hot_encoding(encoders[i], dfs, col)
            data = np.concatenate((data, dataCol), axis=1)
    return encoders, data


def handle_integers(dfs, col):
    data = []
    for df in dfs:
        sumCol = np.sum(df[:, col], axis=0).reshape(1, -1)
        meanCol = np.mean(df[:, col], axis=0).reshape(1, -1)
        # stdCol = np.mean(df[:, col]).reshape(1, -1)
        dataCol = np.concatenate([sumCol, meanCol], axis=1)
        # dataCol = sumCol
        # print(dataCol.shape)
        data.append(dataCol)
    data = np.concatenate(data, axis=0)
    # print(data.shape)
    return data


def handle_integers_feature(dfs, feature):
    # Extract based on correlations
    select_int_col = [True, True, True, True,
                      True, True, False, True, False, False]
    if feature != 8:
        return None
    data = handle_integers(dfs, feature_pos[feature][0])
    for col in tqdm(range(feature_pos[feature][0] + 1, feature_pos[feature][1])):
        i = col - feature_pos[feature][0]
        if select_int_col[i] == False:
            continue
        dataCol = handle_integers(dfs, col)
        data = np.concatenate((data, dataCol), axis=1)
    return data


def save_features(df_train, df_test):
    print ('saving features')
    dataframes = []
    for id in df_train['Id']:
        dfi = load_dataframe(id)
        dataframes.append(dfi.values)
    testdatas = []
    for id in df_test['Id']:
        dfi = load_test_dataframe(id)
        testdatas.append(dfi.values)

    if not os.path.exists(FOLDER):
        os.makedirs(FOLDER)

    print ('saving features 1 to 9')    
    for feat in range(len(feature_pos) - 1):
        print(feat)
        encoders, train = one_hot_encoding_feature([], dataframes, feat)
        encoders, test = one_hot_encoding_feature(encoders, testdatas, feat)
        np.save(FOLDER + '/' + str(feat) + '_train.npy', train)
        np.save(FOLDER + '/' + str(feat) + '_test.npy', test)
        gc.collect()

    train = handle_integers_feature(dataframes, 8)
    test = handle_integers_feature(testdatas, 8)
    np.save(FOLDER + '/8_train.npy', train)
    np.save(FOLDER + '/8_test.npy', test)
    print ('saved features')


def load_freq(feat, postfix):
    data = np.load(FOLDER + "/{}_{}.npy".format(feat, postfix))
    return data


def load_test_freq(feat):
    return load_freq(feat, 'test')


def load_train_freq(feat):
    return load_freq(feat, 'train')


def select_features(feature_selected):
    XTrain = []
    XTest = []
    for feat in range(len(feature_pos)):
        if feature_selected[feat] == False:
            continue
        train = load_train_freq(feat)
        test = load_test_freq(feat)
        XTrain.append(train)
        XTest.append(test)
    XTrain = np.concatenate(XTrain, axis=1)
    XTest = np.concatenate(XTest, axis=1)
    return XTrain, XTest


def all_not_selected(feature_selected):
    for i in range(len(feature_pos)):
        if feature_selected[i] == True:
            return False
    return True


MAX_EVALS = 1
ITER = 50
STOP_ROUND = 5

# tuning
def param_objective(params, train_set, valid_set):
    """Objective function for Gradient Boosting Machine Hyperparameter Tuning"""
    params['num_leaves'] = int(params['num_leaves'])
    params['subsample_for_bin'] = int(params['subsample_for_bin'])
    params['min_child_samples'] = int(params['min_child_samples'])
    # Perform n_fold cross validation with hyperparameters
    # Use early stopping and evalute based on ROC AUC
    bst = lgb.train(params, train_set, ITER, valid_sets=valid_set,
                    early_stopping_rounds=STOP_ROUND)
    bst.save_model('model.txt', num_iteration=bst.best_iteration)

    # Extract the best score
    best_score = bst.best_score['valid_0']['auc']

    # Loss must be minimized
    loss = np.log(1 - best_score)

    # Dictionary with information for evaluation
    return {'loss': loss, 'params': params, 'status': STATUS_OK}


def find_best_params(train_set, valid_set):
    # Define the search space
    space = {
        'boosting_type': 'dart',
        'num_leaves': hp.quniform('num_leaves', 30, 150, 1),
        'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),
        'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),
        'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),
        'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),
        'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),
        'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),
        'metric': 'auc'
    }

    # Trials object to track progress
    bayes_trials = Trials()

    # Optimize
    objective = partial(
        param_objective, train_set=train_set, valid_set=valid_set)
    # Optimize
    bestDict = fmin(fn=objective, space=space, algo=tpe.suggest,
                    max_evals=MAX_EVALS, trials=bayes_trials)
    best = space_eval(space, bestDict)
    best['num_leaves'] = int(best['num_leaves'])
    best['subsample_for_bin'] = int(best['subsample_for_bin'])
    best['min_child_samples'] = int(best['min_child_samples'])
    best['metric'] = 'auc'
    return best


def save_result(df_train, df_test, y):
    print('selecting features')
    # best feature groups
    feature_selected = [True, True, True,
                        False, True, False, False, False, True]
    XTrain, XTest = select_features(feature_selected)
    X_train, X_valid, y_train, y_valid = train_test_split(
        XTrain, y, test_size=0.2, random_state=42)
    train_set = lgb.Dataset(X_train, y_train)
    valid_set = lgb.Dataset(X_valid, y_valid)
    print('tuning')    
    # uncomment this if you want to tune
    # best = find_best_params(train_set, valid_set)
    # the best params that we found
    best = {'boosting_type': 'dart', 'colsample_bytree': 0.6101535421906288, 'learning_rate': 0.19202928417915138, 'metric': 'auc',
            'min_child_samples': 25, 'num_leaves': 130, 'reg_alpha': 0.1367833641980119, 'reg_lambda': 0.99973269788873, 'subsample_for_bin': 80000}
    print('training')    
    lgbModel = lgb.train(best, train_set, ITER,
                         valid_sets=valid_set, early_stopping_rounds=STOP_ROUND)
    model = LGBMClassifier(boosting_type=best['boosting_type'],
                           num_leaves=best['num_leaves'],
                           learning_rate=best['learning_rate'],
                           subsample_for_bin=best['subsample_for_bin'],
                           min_child_samples=best['min_child_samples'],
                           reg_alpha=best['reg_alpha'],
                           reg_lambda=best['reg_lambda'],
                           colsample_bytree=best['colsample_bytree'])
    model.fit(XTrain, y)
    probs = model.predict_proba(XTest, num_iteration=lgbModel.best_iteration)
    YTest = probs[:, 0]
    df_test['Predicted'] = YTest
    df_test.to_csv('test.csv', index=False)
    print('saved result')    


def main():
    df_train = pd.read_csv('train_kaggle.csv')
    df_test = pd.read_csv('sample_solution.csv')
    y = df_train['Label'].values
    # if you have saved features, you can comment save_features
    save_features(df_train, df_test)
    save_result(df_train, df_test, y)


if __name__ == "__main__":
    main()
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           